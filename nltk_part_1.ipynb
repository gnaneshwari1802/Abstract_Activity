{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dV-vizSQwj-o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " Se = '''In 2022, the tech industry saw remarkable growth. Companies like Apple, with a market cap exceeding $2.1 trillion,\n",
        "unveiled new products, while startups secured billions in funding. The pandemic accelerated digital transformation, boosting\n",
        "e-commerce sales by 27%. AI and IoT continued to shape our lives. Amid this, cyberattacks surged by 64%, highlighting the need\n",
        "for robust cybersecurity. As we move forward, the fusion of technology and daily life is evident, promising both innovation and\n",
        "challenges for the years ahead.'''\n",
        "Se\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MRxkdulrxBk5",
        "outputId": "554575af-1caf-48f1-b9cf-1f78a7470eb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In 2022, the tech industry saw remarkable growth. Companies like Apple, with a market cap exceeding $2.1 trillion,\\nunveiled new products, while startups secured billions in funding. The pandemic accelerated digital transformation, boosting\\ne-commerce sales by 27%. AI and IoT continued to shape our lives. Amid this, cyberattacks surged by 64%, highlighting the need\\nfor robust cybersecurity. As we move forward, the fusion of technology and daily life is evident, promising both innovation and\\nchallenges for the years ahead.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(Se)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otXwcNERxP76",
        "outputId": "7397c2fc-de41-40ed-c95f-ee99042ae21f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCUG8ljkx8f5",
        "outputId": "35867380-d4a3-489c-c3a7-a93820d2f1ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(Se)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnlGflYXxUIp",
        "outputId": "7c476a26-a149-436c-debf-6bfaf250aad0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " '2022',\n",
              " ',',\n",
              " 'the',\n",
              " 'tech',\n",
              " 'industry',\n",
              " 'saw',\n",
              " 'remarkable',\n",
              " 'growth',\n",
              " '.',\n",
              " 'Companies',\n",
              " 'like',\n",
              " 'Apple',\n",
              " ',',\n",
              " 'with',\n",
              " 'a',\n",
              " 'market',\n",
              " 'cap',\n",
              " 'exceeding',\n",
              " '$',\n",
              " '2.1',\n",
              " 'trillion',\n",
              " ',',\n",
              " 'unveiled',\n",
              " 'new',\n",
              " 'products',\n",
              " ',',\n",
              " 'while',\n",
              " 'startups',\n",
              " 'secured',\n",
              " 'billions',\n",
              " 'in',\n",
              " 'funding',\n",
              " '.',\n",
              " 'The',\n",
              " 'pandemic',\n",
              " 'accelerated',\n",
              " 'digital',\n",
              " 'transformation',\n",
              " ',',\n",
              " 'boosting',\n",
              " 'e-commerce',\n",
              " 'sales',\n",
              " 'by',\n",
              " '27',\n",
              " '%',\n",
              " '.',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'IoT',\n",
              " 'continued',\n",
              " 'to',\n",
              " 'shape',\n",
              " 'our',\n",
              " 'lives',\n",
              " '.',\n",
              " 'Amid',\n",
              " 'this',\n",
              " ',',\n",
              " 'cyberattacks',\n",
              " 'surged',\n",
              " 'by',\n",
              " '64',\n",
              " '%',\n",
              " ',',\n",
              " 'highlighting',\n",
              " 'the',\n",
              " 'need',\n",
              " 'for',\n",
              " 'robust',\n",
              " 'cybersecurity',\n",
              " '.',\n",
              " 'As',\n",
              " 'we',\n",
              " 'move',\n",
              " 'forward',\n",
              " ',',\n",
              " 'the',\n",
              " 'fusion',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'and',\n",
              " 'daily',\n",
              " 'life',\n",
              " 'is',\n",
              " 'evident',\n",
              " ',',\n",
              " 'promising',\n",
              " 'both',\n",
              " 'innovation',\n",
              " 'and',\n",
              " 'challenges',\n",
              " 'for',\n",
              " 'the',\n",
              " 'years',\n",
              " 'ahead',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_tokenize(Se))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB0bE9s2yE-5",
        "outputId": "9f63af8c-38b0-401e-81c9-ac375e9905e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(Se)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7SyCVcWyI7k",
        "outputId": "12b49692-cd07-4f54-ccf5-364c31b5552e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In 2022, the tech industry saw remarkable growth.',\n",
              " 'Companies like Apple, with a market cap exceeding $2.1 trillion,\\nunveiled new products, while startups secured billions in funding.',\n",
              " 'The pandemic accelerated digital transformation, boosting\\ne-commerce sales by 27%.',\n",
              " 'AI and IoT continued to shape our lives.',\n",
              " 'Amid this, cyberattacks surged by 64%, highlighting the need\\nfor robust cybersecurity.',\n",
              " 'As we move forward, the fusion of technology and daily life is evident, promising both innovation and\\nchallenges for the years ahead.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import blankline_tokenize\n",
        "blankline_tokenize(Se)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSU3ipUIyMmi",
        "outputId": "6478cc81-c174-406c-be43-61f369329dcb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In 2022, the tech industry saw remarkable growth. Companies like Apple, with a market cap exceeding $2.1 trillion,\\nunveiled new products, while startups secured billions in funding. The pandemic accelerated digital transformation, boosting\\ne-commerce sales by 27%. AI and IoT continued to shape our lives. Amid this, cyberattacks surged by 64%, highlighting the need\\nfor robust cybersecurity. As we move forward, the fusion of technology and daily life is evident, promising both innovation and\\nchallenges for the years ahead.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "WhitespaceTokenizer().tokenize(Se)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzBI1sn-yRRo",
        "outputId": "b66fcbaa-d410-4156-8f20-a9cd43794147"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " '2022,',\n",
              " 'the',\n",
              " 'tech',\n",
              " 'industry',\n",
              " 'saw',\n",
              " 'remarkable',\n",
              " 'growth.',\n",
              " 'Companies',\n",
              " 'like',\n",
              " 'Apple,',\n",
              " 'with',\n",
              " 'a',\n",
              " 'market',\n",
              " 'cap',\n",
              " 'exceeding',\n",
              " '$2.1',\n",
              " 'trillion,',\n",
              " 'unveiled',\n",
              " 'new',\n",
              " 'products,',\n",
              " 'while',\n",
              " 'startups',\n",
              " 'secured',\n",
              " 'billions',\n",
              " 'in',\n",
              " 'funding.',\n",
              " 'The',\n",
              " 'pandemic',\n",
              " 'accelerated',\n",
              " 'digital',\n",
              " 'transformation,',\n",
              " 'boosting',\n",
              " 'e-commerce',\n",
              " 'sales',\n",
              " 'by',\n",
              " '27%.',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'IoT',\n",
              " 'continued',\n",
              " 'to',\n",
              " 'shape',\n",
              " 'our',\n",
              " 'lives.',\n",
              " 'Amid',\n",
              " 'this,',\n",
              " 'cyberattacks',\n",
              " 'surged',\n",
              " 'by',\n",
              " '64%,',\n",
              " 'highlighting',\n",
              " 'the',\n",
              " 'need',\n",
              " 'for',\n",
              " 'robust',\n",
              " 'cybersecurity.',\n",
              " 'As',\n",
              " 'we',\n",
              " 'move',\n",
              " 'forward,',\n",
              " 'the',\n",
              " 'fusion',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'and',\n",
              " 'daily',\n",
              " 'life',\n",
              " 'is',\n",
              " 'evident,',\n",
              " 'promising',\n",
              " 'both',\n",
              " 'innovation',\n",
              " 'and',\n",
              " 'challenges',\n",
              " 'for',\n",
              " 'the',\n",
              " 'years',\n",
              " 'ahead.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "wordpunct_tokenize(Se)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5eRqipxyVLb",
        "outputId": "c736f025-a070-4ee2-e92b-8835cff034bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " '2022',\n",
              " ',',\n",
              " 'the',\n",
              " 'tech',\n",
              " 'industry',\n",
              " 'saw',\n",
              " 'remarkable',\n",
              " 'growth',\n",
              " '.',\n",
              " 'Companies',\n",
              " 'like',\n",
              " 'Apple',\n",
              " ',',\n",
              " 'with',\n",
              " 'a',\n",
              " 'market',\n",
              " 'cap',\n",
              " 'exceeding',\n",
              " '$',\n",
              " '2',\n",
              " '.',\n",
              " '1',\n",
              " 'trillion',\n",
              " ',',\n",
              " 'unveiled',\n",
              " 'new',\n",
              " 'products',\n",
              " ',',\n",
              " 'while',\n",
              " 'startups',\n",
              " 'secured',\n",
              " 'billions',\n",
              " 'in',\n",
              " 'funding',\n",
              " '.',\n",
              " 'The',\n",
              " 'pandemic',\n",
              " 'accelerated',\n",
              " 'digital',\n",
              " 'transformation',\n",
              " ',',\n",
              " 'boosting',\n",
              " 'e',\n",
              " '-',\n",
              " 'commerce',\n",
              " 'sales',\n",
              " 'by',\n",
              " '27',\n",
              " '%.',\n",
              " 'AI',\n",
              " 'and',\n",
              " 'IoT',\n",
              " 'continued',\n",
              " 'to',\n",
              " 'shape',\n",
              " 'our',\n",
              " 'lives',\n",
              " '.',\n",
              " 'Amid',\n",
              " 'this',\n",
              " ',',\n",
              " 'cyberattacks',\n",
              " 'surged',\n",
              " 'by',\n",
              " '64',\n",
              " '%,',\n",
              " 'highlighting',\n",
              " 'the',\n",
              " 'need',\n",
              " 'for',\n",
              " 'robust',\n",
              " 'cybersecurity',\n",
              " '.',\n",
              " 'As',\n",
              " 'we',\n",
              " 'move',\n",
              " 'forward',\n",
              " ',',\n",
              " 'the',\n",
              " 'fusion',\n",
              " 'of',\n",
              " 'technology',\n",
              " 'and',\n",
              " 'daily',\n",
              " 'life',\n",
              " 'is',\n",
              " 'evident',\n",
              " ',',\n",
              " 'promising',\n",
              " 'both',\n",
              " 'innovation',\n",
              " 'and',\n",
              " 'challenges',\n",
              " 'for',\n",
              " 'the',\n",
              " 'years',\n",
              " 'ahead',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quote = 'The best and most beautiful things in the world cannot be seen or even touched, theymust be felt with the heart.'\n",
        "quote_token = word_tokenize(quote)\n",
        "quote_token\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jylQn-bFyYov",
        "outputId": "c1bdfa4c-18fc-47ae-fe39-29efbc1cbdaa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'best',\n",
              " 'and',\n",
              " 'most',\n",
              " 'beautiful',\n",
              " 'things',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " 'can',\n",
              " 'not',\n",
              " 'be',\n",
              " 'seen',\n",
              " 'or',\n",
              " 'even',\n",
              " 'touched',\n",
              " ',',\n",
              " 'theymust',\n",
              " 'be',\n",
              " 'felt',\n",
              " 'with',\n",
              " 'the',\n",
              " 'heart',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import bigrams, trigrams, ngrams\n",
        "list(nltk.bigrams(quote_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKx90Lgmyb8n",
        "outputId": "e0c7020b-0d98-41a0-dc94-ec7fb5b75035"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'best'),\n",
              " ('best', 'and'),\n",
              " ('and', 'most'),\n",
              " ('most', 'beautiful'),\n",
              " ('beautiful', 'things'),\n",
              " ('things', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'world'),\n",
              " ('world', 'can'),\n",
              " ('can', 'not'),\n",
              " ('not', 'be'),\n",
              " ('be', 'seen'),\n",
              " ('seen', 'or'),\n",
              " ('or', 'even'),\n",
              " ('even', 'touched'),\n",
              " ('touched', ','),\n",
              " (',', 'theymust'),\n",
              " ('theymust', 'be'),\n",
              " ('be', 'felt'),\n",
              " ('felt', 'with'),\n",
              " ('with', 'the'),\n",
              " ('the', 'heart'),\n",
              " ('heart', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.trigrams(quote_token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyoUSZQzyfS-",
        "outputId": "573b27f0-587c-4725-a1e2-1641ad9c6702"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'best', 'and'),\n",
              " ('best', 'and', 'most'),\n",
              " ('and', 'most', 'beautiful'),\n",
              " ('most', 'beautiful', 'things'),\n",
              " ('beautiful', 'things', 'in'),\n",
              " ('things', 'in', 'the'),\n",
              " ('in', 'the', 'world'),\n",
              " ('the', 'world', 'can'),\n",
              " ('world', 'can', 'not'),\n",
              " ('can', 'not', 'be'),\n",
              " ('not', 'be', 'seen'),\n",
              " ('be', 'seen', 'or'),\n",
              " ('seen', 'or', 'even'),\n",
              " ('or', 'even', 'touched'),\n",
              " ('even', 'touched', ','),\n",
              " ('touched', ',', 'theymust'),\n",
              " (',', 'theymust', 'be'),\n",
              " ('theymust', 'be', 'felt'),\n",
              " ('be', 'felt', 'with'),\n",
              " ('felt', 'with', 'the'),\n",
              " ('with', 'the', 'heart'),\n",
              " ('the', 'heart', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.ngrams(quote_token, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y82wAhyyibp",
        "outputId": "05a8e51a-3d20-420b-d499-1ab6d11d888c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'best', 'and', 'most', 'beautiful'),\n",
              " ('best', 'and', 'most', 'beautiful', 'things'),\n",
              " ('and', 'most', 'beautiful', 'things', 'in'),\n",
              " ('most', 'beautiful', 'things', 'in', 'the'),\n",
              " ('beautiful', 'things', 'in', 'the', 'world'),\n",
              " ('things', 'in', 'the', 'world', 'can'),\n",
              " ('in', 'the', 'world', 'can', 'not'),\n",
              " ('the', 'world', 'can', 'not', 'be'),\n",
              " ('world', 'can', 'not', 'be', 'seen'),\n",
              " ('can', 'not', 'be', 'seen', 'or'),\n",
              " ('not', 'be', 'seen', 'or', 'even'),\n",
              " ('be', 'seen', 'or', 'even', 'touched'),\n",
              " ('seen', 'or', 'even', 'touched', ','),\n",
              " ('or', 'even', 'touched', ',', 'theymust'),\n",
              " ('even', 'touched', ',', 'theymust', 'be'),\n",
              " ('touched', ',', 'theymust', 'be', 'felt'),\n",
              " (',', 'theymust', 'be', 'felt', 'with'),\n",
              " ('theymust', 'be', 'felt', 'with', 'the'),\n",
              " ('be', 'felt', 'with', 'the', 'heart'),\n",
              " ('felt', 'with', 'the', 'heart', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem('Affection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "isrChs0zyl0h",
        "outputId": "15fd21fd-a846-4d1b-9892-daf200e5b870"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'affect'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_stem = ['giving', 'given', 'thanking', 'maximum', 'loving']\n",
        "for words in word_to_stem:\n",
        " print(words + ' : ' + pst.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X37Xwu6bywN4",
        "outputId": "11d28407-50d4-40f2-f01d-2abc6ad7bb0e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giving : give\n",
            "given : given\n",
            "thanking : thank\n",
            "maximum : maximum\n",
            "loving : love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "lst = LancasterStemmer()\n",
        "lst.stem('love')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fe30KZ8fy3jz",
        "outputId": "1efe5ca8-37f0-4385-8b7f-761d0009de6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lov'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for words in word_to_stem:\n",
        " print(words + ' : ' + lst.stem(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCdKdcEBzoTj",
        "outputId": "add05b0a-a35f-4f73-ae2b-bef5916dbeae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giving : giv\n",
            "given : giv\n",
            "thanking : thank\n",
            "maximum : maxim\n",
            "loving : lov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "sbst = SnowballStemmer('english')\n",
        "sbst.stem('loving')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPW6hYsUzq5B",
        "outputId": "b6854fe6-cce4-4ae7-95e2-f73489b98ca6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'love'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for words in word_to_stem:\n",
        " print(words + ' : ' + sbst.stem(words))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DQmnD9g_8af",
        "outputId": "f3ca33ac-e1eb-4ba4-eb69-4bdf19688fec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giving : give\n",
            "given : given\n",
            "thanking : thank\n",
            "maximum : maximum\n",
            "loving : love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1TtMwUjAHsF",
        "outputId": "4ebbbb46-8639-41d0-e553-e9802b21f173"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "word_lem = WordNetLemmatizer()\n",
        "word_lem.lemmatize('loving')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kZfyaTk4__nj",
        "outputId": "393ab110-7233-4339-d138-7b2d68a70baa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'loving'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for words in word_to_stem:\n",
        " print(words + ' : ' + word_lem.lemmatize(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj9DNGV3ANZM",
        "outputId": "487e5cca-fee5-4b57-a77e-2603a244655a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "giving : giving\n",
            "given : given\n",
            "thanking : thanking\n",
            "maximum : maximum\n",
            "loving : loving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PSytgxdAVTe",
        "outputId": "6a400cc8-5833-430b-ed5c-38b24d7bbda0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEWIWBY3AQ0a",
        "outputId": "d8b75c40-86a6-4cdf-9e35-034958020f9a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lHDgDEbAank",
        "outputId": "6a151411-0903-44a8-c57c-bb7911b90946"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "stopwords.words('german')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P4A0iacAebJ",
        "outputId": "45a6faa1-7e48-4df8-b76b-f35250dc37c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aber',\n",
              " 'alle',\n",
              " 'allem',\n",
              " 'allen',\n",
              " 'aller',\n",
              " 'alles',\n",
              " 'als',\n",
              " 'also',\n",
              " 'am',\n",
              " 'an',\n",
              " 'ander',\n",
              " 'andere',\n",
              " 'anderem',\n",
              " 'anderen',\n",
              " 'anderer',\n",
              " 'anderes',\n",
              " 'anderm',\n",
              " 'andern',\n",
              " 'anderr',\n",
              " 'anders',\n",
              " 'auch',\n",
              " 'auf',\n",
              " 'aus',\n",
              " 'bei',\n",
              " 'bin',\n",
              " 'bis',\n",
              " 'bist',\n",
              " 'da',\n",
              " 'damit',\n",
              " 'dann',\n",
              " 'der',\n",
              " 'den',\n",
              " 'des',\n",
              " 'dem',\n",
              " 'die',\n",
              " 'das',\n",
              " 'dass',\n",
              " 'daß',\n",
              " 'derselbe',\n",
              " 'derselben',\n",
              " 'denselben',\n",
              " 'desselben',\n",
              " 'demselben',\n",
              " 'dieselbe',\n",
              " 'dieselben',\n",
              " 'dasselbe',\n",
              " 'dazu',\n",
              " 'dein',\n",
              " 'deine',\n",
              " 'deinem',\n",
              " 'deinen',\n",
              " 'deiner',\n",
              " 'deines',\n",
              " 'denn',\n",
              " 'derer',\n",
              " 'dessen',\n",
              " 'dich',\n",
              " 'dir',\n",
              " 'du',\n",
              " 'dies',\n",
              " 'diese',\n",
              " 'diesem',\n",
              " 'diesen',\n",
              " 'dieser',\n",
              " 'dieses',\n",
              " 'doch',\n",
              " 'dort',\n",
              " 'durch',\n",
              " 'ein',\n",
              " 'eine',\n",
              " 'einem',\n",
              " 'einen',\n",
              " 'einer',\n",
              " 'eines',\n",
              " 'einig',\n",
              " 'einige',\n",
              " 'einigem',\n",
              " 'einigen',\n",
              " 'einiger',\n",
              " 'einiges',\n",
              " 'einmal',\n",
              " 'er',\n",
              " 'ihn',\n",
              " 'ihm',\n",
              " 'es',\n",
              " 'etwas',\n",
              " 'euer',\n",
              " 'eure',\n",
              " 'eurem',\n",
              " 'euren',\n",
              " 'eurer',\n",
              " 'eures',\n",
              " 'für',\n",
              " 'gegen',\n",
              " 'gewesen',\n",
              " 'hab',\n",
              " 'habe',\n",
              " 'haben',\n",
              " 'hat',\n",
              " 'hatte',\n",
              " 'hatten',\n",
              " 'hier',\n",
              " 'hin',\n",
              " 'hinter',\n",
              " 'ich',\n",
              " 'mich',\n",
              " 'mir',\n",
              " 'ihr',\n",
              " 'ihre',\n",
              " 'ihrem',\n",
              " 'ihren',\n",
              " 'ihrer',\n",
              " 'ihres',\n",
              " 'euch',\n",
              " 'im',\n",
              " 'in',\n",
              " 'indem',\n",
              " 'ins',\n",
              " 'ist',\n",
              " 'jede',\n",
              " 'jedem',\n",
              " 'jeden',\n",
              " 'jeder',\n",
              " 'jedes',\n",
              " 'jene',\n",
              " 'jenem',\n",
              " 'jenen',\n",
              " 'jener',\n",
              " 'jenes',\n",
              " 'jetzt',\n",
              " 'kann',\n",
              " 'kein',\n",
              " 'keine',\n",
              " 'keinem',\n",
              " 'keinen',\n",
              " 'keiner',\n",
              " 'keines',\n",
              " 'können',\n",
              " 'könnte',\n",
              " 'machen',\n",
              " 'man',\n",
              " 'manche',\n",
              " 'manchem',\n",
              " 'manchen',\n",
              " 'mancher',\n",
              " 'manches',\n",
              " 'mein',\n",
              " 'meine',\n",
              " 'meinem',\n",
              " 'meinen',\n",
              " 'meiner',\n",
              " 'meines',\n",
              " 'mit',\n",
              " 'muss',\n",
              " 'musste',\n",
              " 'nach',\n",
              " 'nicht',\n",
              " 'nichts',\n",
              " 'noch',\n",
              " 'nun',\n",
              " 'nur',\n",
              " 'ob',\n",
              " 'oder',\n",
              " 'ohne',\n",
              " 'sehr',\n",
              " 'sein',\n",
              " 'seine',\n",
              " 'seinem',\n",
              " 'seinen',\n",
              " 'seiner',\n",
              " 'seines',\n",
              " 'selbst',\n",
              " 'sich',\n",
              " 'sie',\n",
              " 'ihnen',\n",
              " 'sind',\n",
              " 'so',\n",
              " 'solche',\n",
              " 'solchem',\n",
              " 'solchen',\n",
              " 'solcher',\n",
              " 'solches',\n",
              " 'soll',\n",
              " 'sollte',\n",
              " 'sondern',\n",
              " 'sonst',\n",
              " 'über',\n",
              " 'um',\n",
              " 'und',\n",
              " 'uns',\n",
              " 'unsere',\n",
              " 'unserem',\n",
              " 'unseren',\n",
              " 'unser',\n",
              " 'unseres',\n",
              " 'unter',\n",
              " 'viel',\n",
              " 'vom',\n",
              " 'von',\n",
              " 'vor',\n",
              " 'während',\n",
              " 'war',\n",
              " 'waren',\n",
              " 'warst',\n",
              " 'was',\n",
              " 'weg',\n",
              " 'weil',\n",
              " 'weiter',\n",
              " 'welche',\n",
              " 'welchem',\n",
              " 'welchen',\n",
              " 'welcher',\n",
              " 'welches',\n",
              " 'wenn',\n",
              " 'werde',\n",
              " 'werden',\n",
              " 'wie',\n",
              " 'wieder',\n",
              " 'will',\n",
              " 'wir',\n",
              " 'wird',\n",
              " 'wirst',\n",
              " 'wo',\n",
              " 'wollen',\n",
              " 'wollte',\n",
              " 'würde',\n",
              " 'würden',\n",
              " 'zu',\n",
              " 'zum',\n",
              " 'zur',\n",
              " 'zwar',\n",
              " 'zwischen']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(stopwords.words('german'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWVuAR99AooI",
        "outputId": "95b4d0d3-34f4-4509-a018-6e078a798bf2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('chinese')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVfRFdoNAriX",
        "outputId": "fb786925-1585-4a81-8a3a-f7143e923616"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['一',\n",
              " '一下',\n",
              " '一些',\n",
              " '一切',\n",
              " '一则',\n",
              " '一天',\n",
              " '一定',\n",
              " '一方面',\n",
              " '一旦',\n",
              " '一时',\n",
              " '一来',\n",
              " '一样',\n",
              " '一次',\n",
              " '一片',\n",
              " '一直',\n",
              " '一致',\n",
              " '一般',\n",
              " '一起',\n",
              " '一边',\n",
              " '一面',\n",
              " '万一',\n",
              " '上下',\n",
              " '上升',\n",
              " '上去',\n",
              " '上来',\n",
              " '上述',\n",
              " '上面',\n",
              " '下列',\n",
              " '下去',\n",
              " '下来',\n",
              " '下面',\n",
              " '不一',\n",
              " '不久',\n",
              " '不仅',\n",
              " '不会',\n",
              " '不但',\n",
              " '不光',\n",
              " '不单',\n",
              " '不变',\n",
              " '不只',\n",
              " '不可',\n",
              " '不同',\n",
              " '不够',\n",
              " '不如',\n",
              " '不得',\n",
              " '不怕',\n",
              " '不惟',\n",
              " '不成',\n",
              " '不拘',\n",
              " '不敢',\n",
              " '不断',\n",
              " '不是',\n",
              " '不比',\n",
              " '不然',\n",
              " '不特',\n",
              " '不独',\n",
              " '不管',\n",
              " '不能',\n",
              " '不要',\n",
              " '不论',\n",
              " '不足',\n",
              " '不过',\n",
              " '不问',\n",
              " '与',\n",
              " '与其',\n",
              " '与否',\n",
              " '与此同时',\n",
              " '专门',\n",
              " '且',\n",
              " '两者',\n",
              " '严格',\n",
              " '严重',\n",
              " '个',\n",
              " '个人',\n",
              " '个别',\n",
              " '中小',\n",
              " '中间',\n",
              " '丰富',\n",
              " '临',\n",
              " '为',\n",
              " '为主',\n",
              " '为了',\n",
              " '为什么',\n",
              " '为什麽',\n",
              " '为何',\n",
              " '为着',\n",
              " '主张',\n",
              " '主要',\n",
              " '举行',\n",
              " '乃',\n",
              " '乃至',\n",
              " '么',\n",
              " '之',\n",
              " '之一',\n",
              " '之前',\n",
              " '之后',\n",
              " '之後',\n",
              " '之所以',\n",
              " '之类',\n",
              " '乌乎',\n",
              " '乎',\n",
              " '乘',\n",
              " '也',\n",
              " '也好',\n",
              " '也是',\n",
              " '也罢',\n",
              " '了',\n",
              " '了解',\n",
              " '争取',\n",
              " '于',\n",
              " '于是',\n",
              " '于是乎',\n",
              " '云云',\n",
              " '互相',\n",
              " '产生',\n",
              " '人们',\n",
              " '人家',\n",
              " '什么',\n",
              " '什么样',\n",
              " '什麽',\n",
              " '今后',\n",
              " '今天',\n",
              " '今年',\n",
              " '今後',\n",
              " '仍然',\n",
              " '从',\n",
              " '从事',\n",
              " '从而',\n",
              " '他',\n",
              " '他人',\n",
              " '他们',\n",
              " '他的',\n",
              " '代替',\n",
              " '以',\n",
              " '以上',\n",
              " '以下',\n",
              " '以为',\n",
              " '以便',\n",
              " '以免',\n",
              " '以前',\n",
              " '以及',\n",
              " '以后',\n",
              " '以外',\n",
              " '以後',\n",
              " '以来',\n",
              " '以至',\n",
              " '以至于',\n",
              " '以致',\n",
              " '们',\n",
              " '任',\n",
              " '任何',\n",
              " '任凭',\n",
              " '任务',\n",
              " '企图',\n",
              " '伟大',\n",
              " '似乎',\n",
              " '似的',\n",
              " '但',\n",
              " '但是',\n",
              " '何',\n",
              " '何况',\n",
              " '何处',\n",
              " '何时',\n",
              " '作为',\n",
              " '你',\n",
              " '你们',\n",
              " '你的',\n",
              " '使得',\n",
              " '使用',\n",
              " '例如',\n",
              " '依',\n",
              " '依照',\n",
              " '依靠',\n",
              " '促进',\n",
              " '保持',\n",
              " '俺',\n",
              " '俺们',\n",
              " '倘',\n",
              " '倘使',\n",
              " '倘或',\n",
              " '倘然',\n",
              " '倘若',\n",
              " '假使',\n",
              " '假如',\n",
              " '假若',\n",
              " '做到',\n",
              " '像',\n",
              " '允许',\n",
              " '充分',\n",
              " '先后',\n",
              " '先後',\n",
              " '先生',\n",
              " '全部',\n",
              " '全面',\n",
              " '兮',\n",
              " '共同',\n",
              " '关于',\n",
              " '其',\n",
              " '其一',\n",
              " '其中',\n",
              " '其二',\n",
              " '其他',\n",
              " '其余',\n",
              " '其它',\n",
              " '其实',\n",
              " '其次',\n",
              " '具体',\n",
              " '具体地说',\n",
              " '具体说来',\n",
              " '具有',\n",
              " '再者',\n",
              " '再说',\n",
              " '冒',\n",
              " '冲',\n",
              " '决定',\n",
              " '况且',\n",
              " '准备',\n",
              " '几',\n",
              " '几乎',\n",
              " '几时',\n",
              " '凭',\n",
              " '凭借',\n",
              " '出去',\n",
              " '出来',\n",
              " '出现',\n",
              " '分别',\n",
              " '则',\n",
              " '别',\n",
              " '别的',\n",
              " '别说',\n",
              " '到',\n",
              " '前后',\n",
              " '前者',\n",
              " '前进',\n",
              " '前面',\n",
              " '加之',\n",
              " '加以',\n",
              " '加入',\n",
              " '加强',\n",
              " '十分',\n",
              " '即',\n",
              " '即令',\n",
              " '即使',\n",
              " '即便',\n",
              " '即或',\n",
              " '即若',\n",
              " '却不',\n",
              " '原来',\n",
              " '又',\n",
              " '及',\n",
              " '及其',\n",
              " '及时',\n",
              " '及至',\n",
              " '双方',\n",
              " '反之',\n",
              " '反应',\n",
              " '反映',\n",
              " '反过来',\n",
              " '反过来说',\n",
              " '取得',\n",
              " '受到',\n",
              " '变成',\n",
              " '另',\n",
              " '另一方面',\n",
              " '另外',\n",
              " '只是',\n",
              " '只有',\n",
              " '只要',\n",
              " '只限',\n",
              " '叫',\n",
              " '叫做',\n",
              " '召开',\n",
              " '叮咚',\n",
              " '可',\n",
              " '可以',\n",
              " '可是',\n",
              " '可能',\n",
              " '可见',\n",
              " '各',\n",
              " '各个',\n",
              " '各人',\n",
              " '各位',\n",
              " '各地',\n",
              " '各种',\n",
              " '各级',\n",
              " '各自',\n",
              " '合理',\n",
              " '同',\n",
              " '同一',\n",
              " '同时',\n",
              " '同样',\n",
              " '后来',\n",
              " '后面',\n",
              " '向',\n",
              " '向着',\n",
              " '吓',\n",
              " '吗',\n",
              " '否则',\n",
              " '吧',\n",
              " '吧哒',\n",
              " '吱',\n",
              " '呀',\n",
              " '呃',\n",
              " '呕',\n",
              " '呗',\n",
              " '呜',\n",
              " '呜呼',\n",
              " '呢',\n",
              " '周围',\n",
              " '呵',\n",
              " '呸',\n",
              " '呼哧',\n",
              " '咋',\n",
              " '和',\n",
              " '咚',\n",
              " '咦',\n",
              " '咱',\n",
              " '咱们',\n",
              " '咳',\n",
              " '哇',\n",
              " '哈',\n",
              " '哈哈',\n",
              " '哉',\n",
              " '哎',\n",
              " '哎呀',\n",
              " '哎哟',\n",
              " '哗',\n",
              " '哟',\n",
              " '哦',\n",
              " '哩',\n",
              " '哪',\n",
              " '哪个',\n",
              " '哪些',\n",
              " '哪儿',\n",
              " '哪天',\n",
              " '哪年',\n",
              " '哪怕',\n",
              " '哪样',\n",
              " '哪边',\n",
              " '哪里',\n",
              " '哼',\n",
              " '哼唷',\n",
              " '唉',\n",
              " '啊',\n",
              " '啐',\n",
              " '啥',\n",
              " '啦',\n",
              " '啪达',\n",
              " '喂',\n",
              " '喏',\n",
              " '喔唷',\n",
              " '嗡嗡',\n",
              " '嗬',\n",
              " '嗯',\n",
              " '嗳',\n",
              " '嘎',\n",
              " '嘎登',\n",
              " '嘘',\n",
              " '嘛',\n",
              " '嘻',\n",
              " '嘿',\n",
              " '因',\n",
              " '因为',\n",
              " '因此',\n",
              " '因而',\n",
              " '固然',\n",
              " '在',\n",
              " '在下',\n",
              " '地',\n",
              " '坚决',\n",
              " '坚持',\n",
              " '基本',\n",
              " '处理',\n",
              " '复杂',\n",
              " '多',\n",
              " '多少',\n",
              " '多数',\n",
              " '多次',\n",
              " '大力',\n",
              " '大多数',\n",
              " '大大',\n",
              " '大家',\n",
              " '大批',\n",
              " '大约',\n",
              " '大量',\n",
              " '失去',\n",
              " '她',\n",
              " '她们',\n",
              " '她的',\n",
              " '好的',\n",
              " '好象',\n",
              " '如',\n",
              " '如上所述',\n",
              " '如下',\n",
              " '如何',\n",
              " '如其',\n",
              " '如果',\n",
              " '如此',\n",
              " '如若',\n",
              " '存在',\n",
              " '宁',\n",
              " '宁可',\n",
              " '宁愿',\n",
              " '宁肯',\n",
              " '它',\n",
              " '它们',\n",
              " '它们的',\n",
              " '它的',\n",
              " '安全',\n",
              " '完全',\n",
              " '完成',\n",
              " '实现',\n",
              " '实际',\n",
              " '宣布',\n",
              " '容易',\n",
              " '密切',\n",
              " '对',\n",
              " '对于',\n",
              " '对应',\n",
              " '将',\n",
              " '少数',\n",
              " '尔后',\n",
              " '尚且',\n",
              " '尤其',\n",
              " '就',\n",
              " '就是',\n",
              " '就是说',\n",
              " '尽',\n",
              " '尽管',\n",
              " '属于',\n",
              " '岂但',\n",
              " '左右',\n",
              " '巨大',\n",
              " '巩固',\n",
              " '己',\n",
              " '已经',\n",
              " '帮助',\n",
              " '常常',\n",
              " '并',\n",
              " '并不',\n",
              " '并不是',\n",
              " '并且',\n",
              " '并没有',\n",
              " '广大',\n",
              " '广泛',\n",
              " '应当',\n",
              " '应用',\n",
              " '应该',\n",
              " '开外',\n",
              " '开始',\n",
              " '开展',\n",
              " '引起',\n",
              " '强烈',\n",
              " '强调',\n",
              " '归',\n",
              " '当',\n",
              " '当前',\n",
              " '当时',\n",
              " '当然',\n",
              " '当着',\n",
              " '形成',\n",
              " '彻底',\n",
              " '彼',\n",
              " '彼此',\n",
              " '往',\n",
              " '往往',\n",
              " '待',\n",
              " '後来',\n",
              " '後面',\n",
              " '得',\n",
              " '得出',\n",
              " '得到',\n",
              " '心里',\n",
              " '必然',\n",
              " '必要',\n",
              " '必须',\n",
              " '怎',\n",
              " '怎么',\n",
              " '怎么办',\n",
              " '怎么样',\n",
              " '怎样',\n",
              " '怎麽',\n",
              " '总之',\n",
              " '总是',\n",
              " '总的来看',\n",
              " '总的来说',\n",
              " '总的说来',\n",
              " '总结',\n",
              " '总而言之',\n",
              " '恰恰相反',\n",
              " '您',\n",
              " '意思',\n",
              " '愿意',\n",
              " '慢说',\n",
              " '成为',\n",
              " '我',\n",
              " '我们',\n",
              " '我的',\n",
              " '或',\n",
              " '或是',\n",
              " '或者',\n",
              " '战斗',\n",
              " '所',\n",
              " '所以',\n",
              " '所有',\n",
              " '所谓',\n",
              " '打',\n",
              " '扩大',\n",
              " '把',\n",
              " '抑或',\n",
              " '拿',\n",
              " '按',\n",
              " '按照',\n",
              " '换句话说',\n",
              " '换言之',\n",
              " '据',\n",
              " '掌握',\n",
              " '接着',\n",
              " '接著',\n",
              " '故',\n",
              " '故此',\n",
              " '整个',\n",
              " '方便',\n",
              " '方面',\n",
              " '旁人',\n",
              " '无宁',\n",
              " '无法',\n",
              " '无论',\n",
              " '既',\n",
              " '既是',\n",
              " '既然',\n",
              " '时候',\n",
              " '明显',\n",
              " '明确',\n",
              " '是',\n",
              " '是否',\n",
              " '是的',\n",
              " '显然',\n",
              " '显著',\n",
              " '普通',\n",
              " '普遍',\n",
              " '更加',\n",
              " '曾经',\n",
              " '替',\n",
              " '最后',\n",
              " '最大',\n",
              " '最好',\n",
              " '最後',\n",
              " '最近',\n",
              " '最高',\n",
              " '有',\n",
              " '有些',\n",
              " '有关',\n",
              " '有利',\n",
              " '有力',\n",
              " '有所',\n",
              " '有效',\n",
              " '有时',\n",
              " '有点',\n",
              " '有的',\n",
              " '有着',\n",
              " '有著',\n",
              " '望',\n",
              " '朝',\n",
              " '朝着',\n",
              " '本',\n",
              " '本着',\n",
              " '来',\n",
              " '来着',\n",
              " '极了',\n",
              " '构成',\n",
              " '果然',\n",
              " '果真',\n",
              " '某',\n",
              " '某个',\n",
              " '某些',\n",
              " '根据',\n",
              " '根本',\n",
              " '欢迎',\n",
              " '正在',\n",
              " '正如',\n",
              " '正常',\n",
              " '此',\n",
              " '此外',\n",
              " '此时',\n",
              " '此间',\n",
              " '毋宁',\n",
              " '每',\n",
              " '每个',\n",
              " '每天',\n",
              " '每年',\n",
              " '每当',\n",
              " '比',\n",
              " '比如',\n",
              " '比方',\n",
              " '比较',\n",
              " '毫不',\n",
              " '没有',\n",
              " '沿',\n",
              " '沿着',\n",
              " '注意',\n",
              " '深入',\n",
              " '清楚',\n",
              " '满足',\n",
              " '漫说',\n",
              " '焉',\n",
              " '然则',\n",
              " '然后',\n",
              " '然後',\n",
              " '然而',\n",
              " '照',\n",
              " '照着',\n",
              " '特别是',\n",
              " '特殊',\n",
              " '特点',\n",
              " '现代',\n",
              " '现在',\n",
              " '甚么',\n",
              " '甚而',\n",
              " '甚至',\n",
              " '用',\n",
              " '由',\n",
              " '由于',\n",
              " '由此可见',\n",
              " '的',\n",
              " '的话',\n",
              " '目前',\n",
              " '直到',\n",
              " '直接',\n",
              " '相似',\n",
              " '相信',\n",
              " '相反',\n",
              " '相同',\n",
              " '相对',\n",
              " '相对而言',\n",
              " '相应',\n",
              " '相当',\n",
              " '相等',\n",
              " '省得',\n",
              " '看出',\n",
              " '看到',\n",
              " '看来',\n",
              " '看看',\n",
              " '看见',\n",
              " '真是',\n",
              " '真正',\n",
              " '着',\n",
              " '着呢',\n",
              " '矣',\n",
              " '知道',\n",
              " '确定',\n",
              " '离',\n",
              " '积极',\n",
              " '移动',\n",
              " '突出',\n",
              " '突然',\n",
              " '立即',\n",
              " '第',\n",
              " '等',\n",
              " '等等',\n",
              " '管',\n",
              " '紧接着',\n",
              " '纵',\n",
              " '纵令',\n",
              " '纵使',\n",
              " '纵然',\n",
              " '练习',\n",
              " '组成',\n",
              " '经',\n",
              " '经常',\n",
              " '经过',\n",
              " '结合',\n",
              " '结果',\n",
              " '给',\n",
              " '绝对',\n",
              " '继续',\n",
              " '继而',\n",
              " '维持',\n",
              " '综上所述',\n",
              " '罢了',\n",
              " '考虑',\n",
              " '者',\n",
              " '而',\n",
              " '而且',\n",
              " '而况',\n",
              " '而外',\n",
              " '而已',\n",
              " '而是',\n",
              " '而言',\n",
              " '联系',\n",
              " '能',\n",
              " '能否',\n",
              " '能够',\n",
              " '腾',\n",
              " '自',\n",
              " '自个儿',\n",
              " '自从',\n",
              " '自各儿',\n",
              " '自家',\n",
              " '自己',\n",
              " '自身',\n",
              " '至',\n",
              " '至于',\n",
              " '良好',\n",
              " '若',\n",
              " '若是',\n",
              " '若非',\n",
              " '范围',\n",
              " '莫若',\n",
              " '获得',\n",
              " '虽',\n",
              " '虽则',\n",
              " '虽然',\n",
              " '虽说',\n",
              " '行为',\n",
              " '行动',\n",
              " '表明',\n",
              " '表示',\n",
              " '被',\n",
              " '要',\n",
              " '要不',\n",
              " '要不是',\n",
              " '要不然',\n",
              " '要么',\n",
              " '要是',\n",
              " '要求',\n",
              " '规定',\n",
              " '觉得',\n",
              " '认为',\n",
              " '认真',\n",
              " '认识',\n",
              " '让',\n",
              " '许多',\n",
              " '论',\n",
              " '设使',\n",
              " '设若',\n",
              " '该',\n",
              " '说明',\n",
              " '诸位',\n",
              " '谁',\n",
              " '谁知',\n",
              " '赶',\n",
              " '起',\n",
              " '起来',\n",
              " '起见',\n",
              " '趁',\n",
              " '趁着',\n",
              " '越是',\n",
              " '跟',\n",
              " '转动',\n",
              " '转变',\n",
              " '转贴',\n",
              " '较',\n",
              " '较之',\n",
              " '边',\n",
              " '达到',\n",
              " '迅速',\n",
              " '过',\n",
              " '过去',\n",
              " '过来',\n",
              " '运用',\n",
              " '还是',\n",
              " '还有',\n",
              " '这',\n",
              " '这个',\n",
              " '这么',\n",
              " '这么些',\n",
              " '这么样',\n",
              " '这么点儿',\n",
              " '这些',\n",
              " '这会儿',\n",
              " '这儿',\n",
              " '这就是说',\n",
              " '这时',\n",
              " '这样',\n",
              " '这点',\n",
              " '这种',\n",
              " '这边',\n",
              " '这里',\n",
              " '这麽',\n",
              " '进入',\n",
              " '进步',\n",
              " '进而',\n",
              " '进行',\n",
              " '连',\n",
              " '连同',\n",
              " '适应',\n",
              " '适当',\n",
              " '适用',\n",
              " '逐步',\n",
              " '逐渐',\n",
              " '通常',\n",
              " '通过',\n",
              " '造成',\n",
              " '遇到',\n",
              " '遭到',\n",
              " '避免',\n",
              " '那',\n",
              " '那个',\n",
              " '那么',\n",
              " '那么些',\n",
              " '那么样',\n",
              " '那些',\n",
              " '那会儿',\n",
              " '那儿',\n",
              " '那时',\n",
              " '那样',\n",
              " '那边',\n",
              " '那里',\n",
              " '那麽',\n",
              " '部分',\n",
              " '鄙人',\n",
              " '采取',\n",
              " '里面',\n",
              " '重大',\n",
              " '重新',\n",
              " '重要',\n",
              " '鉴于',\n",
              " '问题',\n",
              " '防止',\n",
              " '阿',\n",
              " '附近',\n",
              " '限制',\n",
              " '除',\n",
              " '除了',\n",
              " '除此之外',\n",
              " '除非',\n",
              " '随',\n",
              " '随着',\n",
              " '随著',\n",
              " '集中',\n",
              " '需要',\n",
              " '非但',\n",
              " '非常',\n",
              " '非徒',\n",
              " '靠',\n",
              " '顺',\n",
              " '顺着',\n",
              " '首先',\n",
              " '高兴',\n",
              " '是不是']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords.words('chinese'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXluC0xSAyEo",
        "outputId": "3f781918-e808-4b71-9d50-1f6565fc1c50"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "841"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}